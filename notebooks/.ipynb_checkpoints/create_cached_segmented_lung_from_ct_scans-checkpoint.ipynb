{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/watts/lal/medicine-ai/lung_cancer\n"
     ]
    }
   ],
   "source": [
    "#cd /home/watts/lal/Kaggle/lung_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/arnavkj95/data-science-bowl-2017/candidate-generation-and-luna16-preprocessing\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import skimage, os\n",
    "#os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cuda0,nvcc.fastmath=True,lib.cnmem=0.85'\n",
    "import argparse\n",
    "from time import strftime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "#import theano\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "#from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "#from skimage.measure import label,regionprops, perimeter\n",
    "#from skimage.morphology import binary_dilation, binary_opening\n",
    "#from skimage.filters import roberts, sobel\n",
    "#from skimage import measure, feature\n",
    "#from skimage.segmentation import clear_border\n",
    "#from skimage import data\n",
    "#import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from scipy import ndimage as ndi\n",
    "from numpy.lib.format import open_memmap\n",
    "import dicom\n",
    "import scipy.misc\n",
    "from utils.my_preprocessing import get_segmented_lungs, get_region_of_interest, remove_two_largest_connected\n",
    "from utils.my_luna16_segment_lung_ROI import do_lungmask, do_final_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial\n",
    "\n",
    "# Load the scans in given folder path\n",
    "def read_ct_scan_gzuidhof(folder_path):\n",
    "    #print folder_path\n",
    "    slices = [dicom.read_file(folder_path + '/' + s) for s in os.listdir(folder_path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "def get_pixels(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    \n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness] + scan[0].PixelSpacing, dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_if_image_exists(fname):\n",
    "    fname = os.path.join('data/stage1/stage1/', fname)\n",
    "    return os.path.exists(fname)\n",
    "\n",
    "def check_if_scan_exists(folder):\n",
    "    folder = os.path.join('data/stage1/stage1/', folder)\n",
    "    return os.path.isdir(folder)\n",
    "\n",
    "def get_current_date():\n",
    "    return strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "def load_images(df):\n",
    "    for i, row in df['ImageFile'].iterrows():\n",
    "        img = imread(row)\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ct_scan(folder_name):\n",
    "    # Read the slices from the dicom file\n",
    "    slices = [dicom.read_file(folder_name + filename) for filename in os.listdir(folder_name)]\n",
    "\n",
    "    # Sort the dicom slices in their respective order\n",
    "    slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "\n",
    "    # Get the pixel values for all the slices\n",
    "    slices = np.stack([s.pixel_array for s in slices])\n",
    "    slices[slices == -2000] = 0\n",
    "    return slices\n",
    "def segment_lung_from_ct_scan(ct_scan):\n",
    "    return np.asarray([get_segmented_lungs(slice) for slice in ct_scan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "# def chunks(l, n):\n",
    "#     n = max(1, n)\n",
    "#     return (l[i:i+n] for i in xrange(0, len(l), n))\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_PX_SIZE = 128\n",
    "IMG_PX_SIZE_ORG = 512\n",
    "HM_SLICES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_slices = []\n",
    "\n",
    "def get_new_slices(path):\n",
    "    \n",
    "    #print '01..'\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    #print len(slices)\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    #new_slices = []\n",
    "\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE_ORG,IMG_PX_SIZE_ORG))\n",
    "              for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = int(math.ceil(len(slices) / HM_SLICES))\n",
    "    #print '01..'\n",
    "    #slices = [cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE_ORG,IMG_PX_SIZE_ORG)) \n",
    "    #                  for each_slice in patient_slices]\n",
    "\n",
    "    #slices = patient_slices\n",
    "    #slices[slices == -2000] = 0\n",
    "    #print len(slices)\n",
    "    #print '02..'\n",
    "    #chunk_sizes = math.ceil(len(slices) / HM_SLICES)\n",
    "    #chunk_sizes = len(slices) / HM_SLICES\n",
    "    #print chunk_sizes\n",
    "    #print '03..'\n",
    "    \n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        \n",
    "        #print '031..'\n",
    "        #print len(slice_chunk)\n",
    "        #print len(slice_chunk)\n",
    "        #print slice_chunk[0].shape\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        #print len(slice_chunk)\n",
    "        #print slice_chunk[0].shape\n",
    "        #print '0311..'\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "        #print '032..'\n",
    "        if len(new_slices) == HM_SLICES-1:\n",
    "            new_slices.append(new_slices[-1])\n",
    "\n",
    "        #print '033..'\n",
    "        if len(new_slices) == HM_SLICES-2:\n",
    "            new_slices.append(new_slices[-1])\n",
    "            new_slices.append(new_slices[-1])\n",
    "\n",
    "        #print '034..'\n",
    "        if len(new_slices) == HM_SLICES+2:\n",
    "            new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "            del new_slices[HM_SLICES]\n",
    "            new_slices[HM_SLICES-1] = new_val\n",
    "\n",
    "        #print '035..'\n",
    "        if len(new_slices) == HM_SLICES+1:\n",
    "            new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "            del new_slices[HM_SLICES]\n",
    "            new_slices[HM_SLICES-1] = new_val\n",
    "    return new_slices\n",
    "\n",
    "def get_new_slices2(slices):\n",
    "    \n",
    "    slices = [each_slice.pixel_array for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = int(math.ceil(len(slices) / HM_SLICES))\n",
    "    #print '01..'\n",
    "    #slices = [cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE_ORG,IMG_PX_SIZE_ORG)) \n",
    "    #                  for each_slice in patient_slices]\n",
    "\n",
    "    #slices = patient_slices\n",
    "    #slices[slices == -2000] = 0\n",
    "    #print len(slices)\n",
    "    #print '02..'\n",
    "    #chunk_sizes = math.ceil(len(slices) / HM_SLICES)\n",
    "    #chunk_sizes = len(slices) / HM_SLICES\n",
    "    #print chunk_sizes\n",
    "    #print '03..'\n",
    "    \n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        \n",
    "        #print '031..'\n",
    "        #print len(slice_chunk)\n",
    "        #print len(slice_chunk)\n",
    "        #print slice_chunk[0].shape\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        #print len(slice_chunk)\n",
    "        #print slice_chunk[0].shape\n",
    "        #print '0311..'\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "        #print '032..'\n",
    "        if len(new_slices) == HM_SLICES-1:\n",
    "            new_slices.append(new_slices[-1])\n",
    "\n",
    "        #print '033..'\n",
    "        if len(new_slices) == HM_SLICES-2:\n",
    "            new_slices.append(new_slices[-1])\n",
    "            new_slices.append(new_slices[-1])\n",
    "\n",
    "        #print '034..'\n",
    "        if len(new_slices) == HM_SLICES+2:\n",
    "            new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "            del new_slices[HM_SLICES]\n",
    "            new_slices[HM_SLICES-1] = new_val\n",
    "\n",
    "        #print '035..'\n",
    "        if len(new_slices) == HM_SLICES+1:\n",
    "            new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "            del new_slices[HM_SLICES]\n",
    "            new_slices[HM_SLICES-1] = new_val\n",
    "    return new_slices\n",
    "\n",
    "def get_new_slices3(slices):\n",
    "    \n",
    "    #slices = [each_slice.pixel_array for each_slice in slices]\n",
    "    \n",
    "    \n",
    "    #print '01..'\n",
    "    slices = [cv2.resize(np.array(each_slice),(IMG_PX_SIZE_ORG,IMG_PX_SIZE_ORG)) \n",
    "                      for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = int(math.ceil(len(slices) / HM_SLICES))\n",
    "\n",
    "    #slices = patient_slices\n",
    "    #slices[slices == -2000] = 0\n",
    "    #print len(slices)\n",
    "    #print '02..'\n",
    "    #chunk_sizes = math.ceil(len(slices) / HM_SLICES)\n",
    "    #chunk_sizes = len(slices) / HM_SLICES\n",
    "    #print chunk_sizes\n",
    "    #print '03..'\n",
    "    \n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        \n",
    "        #print '031..'\n",
    "        #print len(slice_chunk)\n",
    "        #print len(slice_chunk)\n",
    "        #print slice_chunk[0].shape\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        #print len(slice_chunk)\n",
    "        #print slice_chunk[0].shape\n",
    "        #print '0311..'\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "        #print '032..'\n",
    "        if len(new_slices) == HM_SLICES-1:\n",
    "            new_slices.append(new_slices[-1])\n",
    "\n",
    "        #print '033..'\n",
    "        if len(new_slices) == HM_SLICES-2:\n",
    "            new_slices.append(new_slices[-1])\n",
    "            new_slices.append(new_slices[-1])\n",
    "\n",
    "        #print '034..'\n",
    "        if len(new_slices) == HM_SLICES+2:\n",
    "            new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "            del new_slices[HM_SLICES]\n",
    "            new_slices[HM_SLICES-1] = new_val\n",
    "\n",
    "        #print '035..'\n",
    "        if len(new_slices) == HM_SLICES+1:\n",
    "            new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "            del new_slices[HM_SLICES]\n",
    "            new_slices[HM_SLICES-1] = new_val\n",
    "    return new_slices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] --size SIZE [--overwrite]\n",
      "__main__.py: error: argument --size is required\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--size', required=True, type=int, help='Original Size of the image')\n",
    "    parser.add_argument('--lung_size', required=True, type=int, help='Size of the lung image')\n",
    "    parser.add_argument('--nslices', required=True, type=int, help='Number of slices')\n",
    "    parser.add_argument('--overwrite', action='store_true', help='Overwirte existing cache')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    IMG_PX_SIZE = args.lung_size\n",
    "    IMG_PX_SIZE_ORG = args.size\n",
    "    HM_SLICES = args.nslices\n",
    "\n",
    "    df = pd.read_csv('data/stage1/stage1_labels.csv')\n",
    "\n",
    "    df['scan_folder'] = df['id']\n",
    "\n",
    "    df['exist'] = df['scan_folder'].apply(check_if_scan_exists)\n",
    "\n",
    "    print '%i does not exists' % (len(df) - df['exist'].sum())\n",
    "    print df[~df['exist']]\n",
    "\n",
    "    df = df[df['exist']]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    y_fname = 'cache/y_%s.npy' % (get_current_date())\n",
    "    y_shape = (len(df))\n",
    "\n",
    "#     if os.path.exists(y_fname) and not args.overwrite:\n",
    "#         print '%s exists. Use --overwrite' % y_fname\n",
    "#         sys.exit(1)\n",
    "\n",
    "   \n",
    "    #y_fp = np.memmap(y_fname, dtype=np.int32, mode='w+', shape=y_shape)\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "#         continue\n",
    "#         if i != 0:\n",
    "#            continue\n",
    "        fname = os.path.join('data/stage1/stage1/', row['scan_folder'])\n",
    "        try:\n",
    "            j = 0\n",
    "            scan_folder = row['scan_folder']\n",
    "            #print scan_folder\n",
    "            patient_slices = read_ct_scan_gzuidhof(fname)\n",
    "            patient_pixels = get_pixels(patient_slices)\n",
    "            #print len(patient_slices)\n",
    "            \n",
    "            #X_images_shape = (len(patient_slices), args.size, args.size)\n",
    "            #print X_images_shape\n",
    "            #X_images_fname = 'cache/X_images_%s_%s_%s.npy' % (scan_folder, args.size, get_current_date())\n",
    "            #print X_images_shape, X_images_fname\n",
    "            #X_images_fp = np.memmap(X_images_fname, dtype=np.float32, mode='w+', shape=X_images_shape)\n",
    "            X_images_fp = np.ndarray([HM_SLICES,IMG_PX_SIZE_ORG,IMG_PX_SIZE_ORG],dtype=np.float32)\n",
    "            \n",
    "            #X_lungmask_shape = (len(patient_slices), args.size, args.size)\n",
    "            #print X_lungmask_shape\n",
    "            #X_lungmask_fname = 'cache/X_lungmask_%s_%s_%s.npy' % (scan_folder, args.size, get_current_date())\n",
    "            # print X_lungmask_shape, X_lungmask_fname\n",
    "            #X_lungmask_fp = np.memmap(X_lungmask_fname, dtype=np.float32, mode='w+', shape=X_lungmask_shape)\n",
    "            X_lungmask_fp = np.ndarray([HM_SLICES,IMG_PX_SIZE_ORG,IMG_PX_SIZE_ORG],dtype=np.float32)\n",
    "            \n",
    "            # each new_slice is an average of chunk_size slices\n",
    "            new_slices = []\n",
    "            #new_slices = get_new_slices(fname)\n",
    "            #pix_resampled, my_spacing = resample(patient_pixels, patient_slices, [1,1,1])\n",
    "            new_slices = get_new_slices2(patient_slices)\n",
    "            #new_slices = get_new_slices3(pix_resampled)\n",
    "            # print len(new_slices)\n",
    "            \n",
    "            for s in new_slices:\n",
    "                #img = patient_pixels[j]\n",
    "                #print '0..'\n",
    "                #print len(s)\n",
    "                img = np.reshape(s, (IMG_PX_SIZE_ORG, IMG_PX_SIZE_ORG))\n",
    "                #print '0a..'\n",
    "                img[img == -2000] = 0\n",
    "                #print '0b..'\n",
    "                #print img\n",
    "                nz = np.count_nonzero(img)\n",
    "                if nz == 0:\n",
    "                    print 'slice all zero..........'\n",
    "                #print '1..'\n",
    "                X_images_fp[j] = img\n",
    "                #X_images_fp.flush()\n",
    "                #print '2..'\n",
    "                lungmask = do_lungmask(img)\n",
    "                #print '3..'\n",
    "                X_lungmask_fp[j] = lungmask\n",
    "                #X_lungmask_fp.flush()\n",
    "                #print '4..'\n",
    "                j = j+1\n",
    "            #print j\n",
    "            assert(j == len(new_slices))\n",
    "            #label = row['cancer']\n",
    "            #y_fp[i] = label\n",
    "            #y_fp.flush()\n",
    "            \n",
    "            #X_images_fp = X_lungmask_fp*X_images_fp\n",
    "            \n",
    "            # X_segmented_images_shape = (len(X_images_fp), args.size, args.size)\n",
    "            # print X_segmented_images_shape\n",
    "            X_segmented_images_fname = 'cache/X_segmented_lungs_%s_%s_%s_%s.npy' % (scan_folder, HM_SLICES, IMG_PX_SIZE, IMG_PX_SIZE)\n",
    "            #print X_segmented_images_fname\n",
    "            #X_segmented_images_fp = np.memmap(X_train_images_fname, dtype=np.int64, mode='w+', shape=X_train_images_shape)\n",
    "            \n",
    "            #print '0..'\n",
    "            #segmented_lungs = []\n",
    "            segmented_lungs = np.ndarray([1,HM_SLICES,IMG_PX_SIZE,IMG_PX_SIZE],\n",
    "                                         dtype=np.float32)\n",
    "            # print len(new_slices)\n",
    "            for k in range(len(new_slices)):\n",
    "                img = X_images_fp[k]\n",
    "                mask = X_lungmask_fp[k]\n",
    "                #print img.shape\n",
    "                #print mask.shape\n",
    "                try:\n",
    "                    #print '0a..'\n",
    "                    new_img = do_final_processing(img, mask)\n",
    "                    #print new_img.shape\n",
    "                    #print '0b..'\n",
    "                    if new_img is not None:\n",
    "                        #X_segmented_images_fp[k] = new_img\n",
    "                        #X_segmented_images_fp.flush()\n",
    "                        #segmented_lungs.append(new_img)\n",
    "                        #print '1..'\n",
    "                        new_img = resize(new_img,[IMG_PX_SIZE,IMG_PX_SIZE])\n",
    "                        #print new_img.shape\n",
    "                        #print '2..'\n",
    "                        #segmented_lungs.append(new_img)\n",
    "                        segmented_lungs[0, k] = new_img\n",
    "                        #print '3..'\n",
    "                        \n",
    "                except:\n",
    "                    print 'failed in %s' %k\n",
    "                    sys.exit(1)\n",
    "            #segmented_lung_images = np.stack([img for img in segmented_lungs])\n",
    "            np.save(X_segmented_images_fname, segmented_lungs) \n",
    "            #print 'Deleting %s %s ..' % (X_images_fname, X_lungmask_fname)\n",
    "            # now delete imgs and masks\n",
    "            #os.remove(X_images_fname) \n",
    "            #os.remove(X_lungmask_fname) \n",
    "        except:\n",
    "            print '%s has failed' % i\n",
    "            #sys.exit(1)\n",
    "    # now read, used for 2D segmentation \n",
    "#     num_images = 1397\n",
    "#     num_seg_slices = 0\n",
    "#     num_slices = HM_SLICES\n",
    "#     img_width = args.lung_size\n",
    "#     img_height = args.lung_size\n",
    "#     my_out_seg_lung = np.ndarray([(num_images* num_slices),1,img_width,img_height],dtype=np.float32)\n",
    "#     for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "#         scan_folder = row['scan_folder']\n",
    "#         X_segmented_lungs_fname = 'cache/X_segmented_lungs_%s_%s_%s_%s.npy' % (scan_folder, HM_SLICES, IMG_PX_SIZE, IMG_PX_SIZE)\n",
    "#         seg_lung = np.load(X_segmented_lungs_fname)\n",
    "#         assert(seg_lung.shape[1] == HM_SLICES)\n",
    "#         for j in range(seg_lung.shape[1]):\n",
    "#             lung_slice = seg_lung[0,j]\n",
    "#             assert(lung_slice.shape[0] == img_width)\n",
    "#             my_fname = 'cache/X_segmented_lung_%s_%d_%d_%d' % (scan_folder,j,img_width, img_height)\n",
    "#             np.save(my_fname, lung_slice)\n",
    "#             my_out_seg_lung[num_seg_slices,0] = lung_slice\n",
    "#             num_seg_slices += 1\n",
    "#     print num_seg_slices\n",
    "#     assert(num_seg_slices == num_images * num_slices)\n",
    "print 'Done'\n",
    "now = datetime.datetime.now()\n",
    "print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
