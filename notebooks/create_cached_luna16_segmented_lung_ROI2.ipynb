{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "from random import randint, choice\n",
    "try:\n",
    "    from tqdm import tqdm # long waits are not fun\n",
    "except:\n",
    "    print('TQDM does make much nicer wait bars...')\n",
    "    tqdm = lambda x: x\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_path = \"/home/watts/lal/Kaggle/lung_cancer/cache/luna16/512_512_16/\"\n",
    "file_list=glob(working_path+\"images_*.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_slices = 16\n",
    "img_width = 128\n",
    "img_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [1:44:58<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for fcount, img_file in enumerate(tqdm(file_list)):\n",
    "#     continue\n",
    "#     if fcount != 0:\n",
    "#         continue\n",
    "    # I ran into an error when using Kmean on np.float16, so I'm using np.float64 here\n",
    "    imgs_to_process = np.load(img_file).astype(np.float64) \n",
    "    # print \"on image\", img_file\n",
    "    for i in range(len(imgs_to_process)):\n",
    "        img = imgs_to_process[i]\n",
    "        #Standardize the pixel values\n",
    "        mean = np.mean(img)\n",
    "        std = np.std(img)\n",
    "        img = img-mean\n",
    "        img = img/std\n",
    "        # Find the average pixel value near the lungs\n",
    "        # to renormalize washed out images\n",
    "        middle = img[100:400,100:400] \n",
    "        mean = np.mean(middle)  \n",
    "        max = np.max(img)\n",
    "        min = np.min(img)\n",
    "        # To improve threshold finding, I'm moving the \n",
    "        # underflow and overflow on the pixel spectrum\n",
    "        img[img==max]=mean\n",
    "        img[img==min]=mean\n",
    "        #\n",
    "        # Using Kmeans to separate foreground (radio-opaque tissue)\n",
    "        # and background (radio transparent tissue ie lungs)\n",
    "        # Doing this only on the center of the image to avoid \n",
    "        # the non-tissue parts of the image as much as possible\n",
    "        #\n",
    "        kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n",
    "        centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "        threshold = np.mean(centers)\n",
    "        thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n",
    "        #\n",
    "        # I found an initial erosion helful for removing graininess from some of the regions\n",
    "        # and then large dialation is used to make the lung region \n",
    "        # engulf the vessels and incursions into the lung cavity by \n",
    "        # radio opaque tissue\n",
    "        #\n",
    "        eroded = morphology.erosion(thresh_img,np.ones([4,4]))\n",
    "        dilation = morphology.dilation(eroded,np.ones([10,10]))\n",
    "        #\n",
    "        #  Label each region and obtain the region properties\n",
    "        #  The background region is removed by removing regions \n",
    "        #  with a bbox that is to large in either dimnsion\n",
    "        #  Also, the lungs are generally far away from the top \n",
    "        #  and bottom of the image, so any regions that are too\n",
    "        #  close to the top and bottom are removed\n",
    "        #  This does not produce a perfect segmentation of the lungs\n",
    "        #  from the image, but it is surprisingly good considering its\n",
    "        #  simplicity. \n",
    "        #\n",
    "        labels = measure.label(dilation)\n",
    "        label_vals = np.unique(labels)\n",
    "        regions = measure.regionprops(labels)\n",
    "        good_labels = []\n",
    "        for prop in regions:\n",
    "            B = prop.bbox\n",
    "            if B[2]-B[0]<475 and B[3]-B[1]<475 and B[0]>40 and B[2]<472:\n",
    "                good_labels.append(prop.label)\n",
    "        mask = np.ndarray([512,512],dtype=np.int8)\n",
    "        #mask = np.ndarray([41,41],dtype=np.int8)\n",
    "        mask[:] = 0\n",
    "        #\n",
    "        #  The mask here is the mask for the lungs--not the nodes\n",
    "        #  After just the lungs are left, we do another large dilation\n",
    "        #  in order to fill in and out the lung mask \n",
    "        #\n",
    "        for N in good_labels:\n",
    "            mask = mask + np.where(labels==N,1,0)\n",
    "        mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n",
    "        imgs_to_process[i] = mask\n",
    "    np.save(img_file.replace(\"images\",\"lungmask\"),imgs_to_process)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [18:52<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#    Here we're applying the masks and cropping and resizing the image\n",
    "#\n",
    "\n",
    "# num_slices = 16\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "#warnings.simplefilter(\"error\")\n",
    "\n",
    "file_list=glob(working_path+\"lungmask_*.npy\")\n",
    "out_images = []      #final set of images\n",
    "out_nodemasks = []   #final set of nodemasks\n",
    "num_empty_slices = 0\n",
    "num_images = 0\n",
    "try:\n",
    "    for fcount, fname in enumerate(tqdm(file_list)):\n",
    "#         if fcount != 199:\n",
    "#             continue\n",
    "        #print \"working on file \", fname\n",
    "        imgs_to_process = np.load(fname.replace(\"lungmask\",\"images\"))\n",
    "        masks = np.load(fname)\n",
    "        node_masks = np.load(fname.replace(\"lungmask\",\"masks\"))\n",
    "        my_out_images = []\n",
    "        my_out_nodemasks = []\n",
    "        my_pad_img = imgs_to_process[0]\n",
    "        my_pad_nodemask = node_masks[0]\n",
    "        #print imgs_to_process.shape\n",
    "        for i in range(len(imgs_to_process)):\n",
    "            mask = masks[i]\n",
    "            node_mask = node_masks[i]\n",
    "            img = imgs_to_process[i]\n",
    "            new_size = [512,512]   # we're scaling back up to the original size of the image\n",
    "            # new_size = [40,40]   \n",
    "            img= mask*img          # apply lung mask\n",
    "            empty_slice = not img[mask>0].any()\n",
    "            if empty_slice == True:\n",
    "                num_empty_slices = num_empty_slices + 1\n",
    "            #    continue\n",
    "            #\n",
    "            # renormalizing the masked image (in the mask region)\n",
    "            #\n",
    "            nz = np.count_nonzero(img[mask >0])\n",
    "            if nz == 0:\n",
    "                continue\n",
    "            new_mean = np.mean(img[mask>0])  \n",
    "            new_std = np.std(img[mask>0])\n",
    "            #\n",
    "            #  Pulling the background color up to the lower end\n",
    "            #  of the pixel range for the lungs\n",
    "            #\n",
    "            old_min = np.min(img)       # background color\n",
    "            img[img==old_min] = new_mean-1.2*new_std   # resetting backgound color\n",
    "            img = img-new_mean\n",
    "            img = img/new_std\n",
    "            #make image bounding box  (min row, min col, max row, max col)\n",
    "            labels = measure.label(mask)\n",
    "            regions = measure.regionprops(labels)\n",
    "            #\n",
    "            # Finding the global min and max row over all regions\n",
    "            #\n",
    "            min_row = 512\n",
    "            #min_row = 40\n",
    "            max_row = 0\n",
    "            min_col = 512\n",
    "            #min_col = 40\n",
    "            max_col = 0\n",
    "            for prop in regions:\n",
    "                B = prop.bbox\n",
    "                if min_row > B[0]:\n",
    "                    min_row = B[0]\n",
    "                if min_col > B[1]:\n",
    "                    min_col = B[1]\n",
    "                if max_row < B[2]:\n",
    "                    max_row = B[2]\n",
    "                if max_col < B[3]:\n",
    "                    max_col = B[3]\n",
    "            width = max_col-min_col\n",
    "            height = max_row - min_row\n",
    "            if width > height:\n",
    "                max_row=min_row+width\n",
    "            else:\n",
    "                max_col = min_col+height\n",
    "            # \n",
    "            # cropping the image down to the bounding box for all regions\n",
    "            # (there's probably an skimage command that can do this in one line)\n",
    "            # \n",
    "            img = img[min_row:max_row,min_col:max_col]\n",
    "            mask =  mask[min_row:max_row,min_col:max_col]\n",
    "            if max_row-min_row <5 or max_col-min_col<5:  # skipping all images with no good regions\n",
    "                pass\n",
    "            else:\n",
    "                # moving range to -1 to 1 to accomodate the resize function\n",
    "                nz = np.count_nonzero(img)\n",
    "                if nz == 0:\n",
    "                    continue\n",
    "                mean = np.mean(img)\n",
    "                img = img - mean\n",
    "                nz = np.count_nonzero(img)\n",
    "                if nz == 0:\n",
    "                    continue\n",
    "                min = np.min(img)\n",
    "                max = np.max(img)\n",
    "                img = img/(max-min)\n",
    "                new_img = resize(img,[512,512])\n",
    "                new_node_mask = resize(node_mask[min_row:max_row,min_col:max_col],[512,512])\n",
    "                nz1 = np.count_nonzero(node_mask)\n",
    "                nz2 = np.count_nonzero(new_node_mask)\n",
    "                if nz1 == 0 or nz2 == 0:\n",
    "#                     print fcount, i\n",
    "#                     print nz1, nz2\n",
    "#                     print min_row, max_row, min_col, max_col\n",
    "                    continue\n",
    "                my_pad_img = new_img\n",
    "                my_pad_nodemask = new_node_mask\n",
    "                out_images.append(new_img)\n",
    "                out_nodemasks.append(new_node_mask)\n",
    "                my_out_images.append(new_img)\n",
    "                my_out_nodemasks.append(new_node_mask)\n",
    "        #print len(my_out_images)\n",
    "        if len(my_out_images) == 0:\n",
    "            continue\n",
    "        while(len(my_out_images) < num_slices):\n",
    "            index = randint(0, len(my_out_images)-1)\n",
    "            my_pad_image = my_out_images[index]\n",
    "            my_pad_nodemask = my_out_nodemasks[index]\n",
    "            my_out_images.append(my_pad_img)\n",
    "            my_out_nodemasks.append(my_pad_nodemask)\n",
    "        #print len(my_out_images)\n",
    "        my_fname = fname.replace(\"lungmask\",\"my_images\")\n",
    "        my_nodemask_fname = fname.replace(\"lungmask\",\"my_masks\")\n",
    "        # print 'writing %s, %s' %(my_fname, my_nodemask_fname)\n",
    "        num_images += 1\n",
    "        np.save(my_fname,my_out_images)\n",
    "        np.save(my_nodemask_fname,my_out_nodemasks) \n",
    "except:\n",
    "    print traceback.format_exc()\n",
    "print num_empty_slices\n",
    "print num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Writing out images and masks as 1 channel arrays for input into network\n",
    "#\n",
    "#final_images = np.ndarray([num_images,1,512,512],dtype=np.float32)\n",
    "#final_masks = np.ndarray([num_images,1,512,512],dtype=np.float32)\n",
    "#final_images = np.ndarray([num_images,1,40,40],dtype=np.float32)\n",
    "#final_masks = np.ndarray([num_images,1,40,40],dtype=np.float32)\n",
    "# for i in range(num_images):\n",
    "#     final_images[i,0] = out_images[i]\n",
    "#     final_masks[i,0] = out_nodemasks[i]\n",
    "\n",
    "# rand_i = np.random.choice(range(num_images),size=num_images,replace=False)\n",
    "# test_i = int(0.2*num_images)\n",
    "# np.save(working_path+\"trainImages_40_40.npy\",final_images[rand_i[test_i:]])\n",
    "# np.save(working_path+\"trainMasks_40_40.npy\",final_masks[rand_i[test_i:]])\n",
    "# np.save(working_path+\"testImages_40_40.npy\",final_images[rand_i[:test_i]])\n",
    "# np.save(working_path+\"testMasks_40_40.npy\",final_masks[rand_i[:test_i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(working_path+\"myTrainImages_40_40.npy\",final_images)\n",
    "# np.save(working_path+\"myTrainMasks_40_40.npy\",final_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1155/1155 [06:13<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total masks: 1155, num zeros: 0\n",
      "writing /home/watts/lal/Kaggle/lung_cancer/cache/luna16/512_512_16/my_t_mask_16_128_128.npy\n",
      "Done\n",
      "2017-04-07 19:23:38.078868\n"
     ]
    }
   ],
   "source": [
    "num_images = 1155\n",
    "file_list=glob(working_path+\"my_masks_*.npy\")\n",
    "total_masks = 0\n",
    "num_zeros = 0\n",
    "my_final_masks = np.ndarray([num_images,1,num_slices,img_width,img_height],dtype=np.float32)\n",
    "for i, mask_file in enumerate(tqdm(file_list)):\n",
    "    zero_mask = 0\n",
    "    masks = np.load(mask_file)\n",
    "    masks = resize(masks,[num_slices,img_width,img_height])\n",
    "    if (num_slices, img_height, img_width) != masks.shape:\n",
    "        print i\n",
    "        print masks.shape\n",
    "    #print final_images[i,0].shape\n",
    "    \n",
    "    for j in range(num_slices):\n",
    "        mask = masks[j]\n",
    "        nz = np.count_nonzero(mask)\n",
    "        if nz == 0:\n",
    "            print 'mask %d in slice %s is all zero..' % (j, mask_file)\n",
    "            zero_mask = 1\n",
    "            continue\n",
    "    if zero_mask == 1:\n",
    "        continue\n",
    "        \n",
    "    nz = np.count_nonzero(masks)\n",
    "    if nz == 0:\n",
    "        print 'mask file %s is all 0' % mask_file\n",
    "        num_zeros = num_zeros + 1\n",
    "        continue\n",
    "    my_final_masks[i,0] = masks\n",
    "    total_masks = total_masks + 1\n",
    "print('Total masks: %d, num zeros: %d' %(total_masks, num_zeros))\n",
    "    \n",
    "my_fname = working_path+'my_t_mask_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "print 'writing %s' % my_fname\n",
    "np.save(my_fname,my_final_masks)\n",
    "print 'Done'\n",
    "now = datetime.datetime.now()\n",
    "print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1155/1155 [08:02<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 1155, num zeros: 0\n",
      "writing /home/watts/lal/Kaggle/lung_cancer/cache/luna16/512_512_16/my_t_image_16_128_128.npy\n",
      "Done\n",
      "2017-04-07 19:31:50.872766\n"
     ]
    }
   ],
   "source": [
    "num_images = 1155\n",
    "total_images = 0\n",
    "num_zeros = 0\n",
    "\n",
    "my_final_images = np.ndarray([num_images,1,num_slices,img_height,img_width],dtype=np.float32)\n",
    "file_list=glob(working_path+\"my_images_*.npy\")\n",
    "for i, img_file in enumerate(tqdm(file_list)):\n",
    "    zero_image = 0\n",
    "    #print img_file\n",
    "    imgs = np.load(img_file)\n",
    "    imgs = resize(imgs,[num_slices, img_width,img_height])\n",
    "    if (num_slices, img_height, img_width) != imgs.shape:\n",
    "        print i\n",
    "        print imgs.shape\n",
    "    #print final_images[i,0].shape\n",
    "    for j in range(num_slices):\n",
    "        img = imgs[j]\n",
    "        nz = np.count_nonzero(img)\n",
    "        if nz == 0:\n",
    "            print 'image %d in slice %s is all zero..' % (i, img_file)\n",
    "            zero_image = 1\n",
    "            continue\n",
    "    if zero_image == 1:\n",
    "        continue\n",
    "    nz = np.count_nonzero(imgs)\n",
    "    if nz == 0:\n",
    "        print 'slice %s is all zero..' % img_file\n",
    "        num_zeros = num_zeros + 1\n",
    "        continue\n",
    "    my_final_images[i,0] = imgs\n",
    "    total_images = total_images + 1\n",
    "\n",
    "print('Total images: %d, num zeros: %d' %(total_images, num_zeros))\n",
    "my_fname = working_path+'my_t_image_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "print 'writing %s' % my_fname\n",
    "np.save(my_fname,my_final_images)\n",
    "print 'Done'\n",
    "now = datetime.datetime.now()\n",
    "print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 1, 16, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "my_final_images = np.load(my_fname)\n",
    "print my_final_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num_zero = 0\n",
    "for i in range(my_final_images.shape[0]):\n",
    "    #for j in range(my_final_images.shape[2]):\n",
    "    img = my_final_images[i,0]\n",
    "    if (num_slices, img_height, img_width) != img.shape:\n",
    "        print i\n",
    "        print img.shape\n",
    "    nz = np.count_nonzero(img)\n",
    "    if nz == 0:\n",
    "        num_zero += 1\n",
    "print num_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing train and test images my_train_images_16_128_128.npy and my_test_images_16_128_128.npy..\n",
      "Done\n",
      "2017-04-07 19:32:07.140143\n"
     ]
    }
   ],
   "source": [
    "rand_i = np.random.choice(range(num_images),size=num_images,replace=False)\n",
    "test_i = int(0.2*num_images)\n",
    "\n",
    "my_fname_train = 'my_train_images_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "my_fname_test = 'my_test_images_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "print 'writing train and test images %s and %s..' % (my_fname_train, my_fname_test)\n",
    "np.save(working_path+my_fname_train,my_final_images[rand_i[test_i:]])\n",
    "np.save(working_path+my_fname_test,my_final_images[rand_i[:test_i]])\n",
    "print 'Done'\n",
    "now = datetime.datetime.now()\n",
    "print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 1, 16, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "my_fname = working_path+'my_t_mask_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "my_final_masks = np.load(my_fname)\n",
    "print my_final_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num_zero = 0\n",
    "for i in range(my_final_masks.shape[0]):\n",
    "    #for j in range(my_final_masks.shape[2]):\n",
    "    img = my_final_masks[i,0]\n",
    "    nz = np.count_nonzero(img)\n",
    "    if nz == 0:\n",
    "    #    print 'slice is 0...'\n",
    "        num_zero += 1\n",
    "print num_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing train and test masks my_train_masks_16_128_128.npy and my_test_masks_16_128_128.npy..\n",
      "Done\n",
      "2017-04-07 19:32:27.366615\n"
     ]
    }
   ],
   "source": [
    "my_fname_train = 'my_train_masks_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "my_fname_test = 'my_test_masks_%d_%d_%d.npy' % (num_slices, img_width, img_height)  \n",
    "print 'writing train and test masks %s and %s..' % (my_fname_train, my_fname_test)\n",
    "np.save(working_path+my_fname_train,my_final_masks[rand_i[test_i:]])\n",
    "np.save(working_path+my_fname_test,my_final_masks[rand_i[:test_i]])\n",
    "print 'Done'\n",
    "now = datetime.datetime.now()\n",
    "print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 1, 16, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "my_fname = working_path+'my_t_image_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "my_final_images = np.load(my_fname)\n",
    "print my_final_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [00:05<00:00, 209.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18592\n",
      "Done\n",
      "2017-04-06 04:28:58.936474\n"
     ]
    }
   ],
   "source": [
    "# num_image = 0\n",
    "# my_out_image = np.ndarray([(num_images* num_slices),1,img_width,img_height],dtype=np.float32)\n",
    "# for i in tqdm(range(my_final_images.shape[0])):\n",
    "#     imgs = my_final_images[i,0]\n",
    "#     assert(imgs.shape[0] == num_slices)\n",
    "#     for j in range(imgs.shape[0]):\n",
    "#         img = imgs[j]\n",
    "#         my_fname = 'my_image_%d_%d_%d' % (num_image, img_width, img_height)\n",
    "#         np.save(working_path+my_fname, img)\n",
    "#         my_out_image[num_image,0] = img\n",
    "#         num_image += 1\n",
    "# print num_image\n",
    "# assert(num_image == num_images * num_slices)\n",
    "# my_fname = 'my_train_image_%d_%d' % (img_width, img_height)\n",
    "# np.save(working_path+my_fname, my_out_image)\n",
    "# print 'Done'\n",
    "# now = datetime.datetime.now()\n",
    "# print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 1, 16, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# my_fname = working_path+'my_t_mask_%d_%d_%d.npy' % (num_slices, img_width, img_height)\n",
    "# my_final_masks = np.load(my_fname)\n",
    "# print my_final_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1162/1162 [00:04<00:00, 236.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18592\n",
      "Done\n",
      "2017-04-06 04:29:18.283332\n"
     ]
    }
   ],
   "source": [
    "# num_mask = 0\n",
    "# my_out_mask = np.ndarray([(num_images* num_slices),1,img_width,img_height],dtype=np.float32)\n",
    "# for i in tqdm(range(my_final_masks.shape[0])):\n",
    "#     masks = my_final_masks[i,0]\n",
    "#     assert(masks.shape[0] == num_slices)\n",
    "#     for j in range(masks.shape[0]):\n",
    "#         mask = masks[j]\n",
    "#         my_fname = 'my_mask_%d_%d_%d' % (num_mask, img_width, img_height)\n",
    "#         np.save(working_path+my_fname, mask)\n",
    "#         my_out_mask[num_mask,0] = mask\n",
    "#         num_mask += 1\n",
    "# print num_mask\n",
    "# assert(num_mask == total_masks * num_slices)\n",
    "# my_fname = 'my_train_mask_%d_%d' % (img_width, img_height)\n",
    "# np.save(working_path+my_fname, my_out_mask)\n",
    "# print 'Done'\n",
    "# now = datetime.datetime.now()\n",
    "# print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing train and test images my_train_image_128_128.npy and my_test_image_128_128.npy..\n",
      "Done\n",
      "2017-04-06 04:29:45.682288\n"
     ]
    }
   ],
   "source": [
    "# rand_i = np.random.choice(range(num_image),size=num_image,replace=False)\n",
    "# test_i = int(0.2*num_image)\n",
    "\n",
    "# my_fname_train = 'my_train_image_%d_%d.npy' % (img_width, img_height)\n",
    "# my_fname_test = 'my_test_image_%d_%d.npy' % (img_width, img_height)\n",
    "# print 'writing train and test images %s and %s..' % (my_fname_train, my_fname_test)\n",
    "# np.save(working_path+my_fname_train,my_out_image[rand_i[test_i:]])\n",
    "# np.save(working_path+my_fname_test,my_out_image[rand_i[:test_i]])\n",
    "# print 'Done'\n",
    "# now = datetime.datetime.now()\n",
    "# print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing train and test masks my_train_mask_128_128.npy and my_test_mask_128_128.npy..\n",
      "Done\n",
      "2017-04-06 04:29:59.049330\n"
     ]
    }
   ],
   "source": [
    "# my_fname_train = 'my_train_mask_%d_%d.npy' % (img_width, img_height)\n",
    "# my_fname_test = 'my_test_mask_%d_%d.npy' % (img_width, img_height)\n",
    "# print 'writing train and test masks %s and %s..' % (my_fname_train, my_fname_test)\n",
    "# np.save(working_path+my_fname_train,my_out_mask[rand_i[test_i:]])\n",
    "# np.save(working_path+my_fname_test,my_out_mask[rand_i[:test_i]])\n",
    "# print 'Done'\n",
    "# now = datetime.datetime.now()\n",
    "# print now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
